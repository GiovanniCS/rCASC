---
title: "CASC supplementary data"
author: "Luca Alessandr√¨, Marco Beccuti, Maddalena Arigoni, Martina Olivero, Greta Romano, Francesca Cordero and Raffaele A Calogero"
date: "8/21/2018"
output: pdf_document

toc: yes
header-includes:
- \usepackage{makeidx}
- \makeindex
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'h')
```

## CASC: a single cell analysis workflow designed to provide data reproducibility

Because of the massive data generation given by the omics platforms the [*reproducibility crisis*](https://en.wikipedia.org/wiki/Replication_crisis) is becoming a very important point to guarantee robust and reliable results to the research community [[*Nature, 6 July 2018*](https://www.nature.com/collections/prbfkwmwvz)].
\newline
Our group is deeply involved in developing workflows that guarantee both **functional** (i.e. the information about data and the utilized tools are saved in terms of meta-data) and **computation** reproducibility (i.e. the real image of the computation environment used to generate the data is stored). For this reason we are managing a bioinformatics community called [*reproducible-bioinformatics.org*](http://www.reproducible-bioinformatics.org/) [*Kulkarni et al. BMC Bioinformatics, in press*] designed to provide to the biological community a reproducible bioinformatics ecosystem  [[*Beccuti et al. Bioinformatics 2018*](https://academic.oup.com/bioinformatics/article/34/5/871/4562334)]. 
\newline
CASC, Cluster Analysis of Single Cells, is part of the [*reproducible-bioinformatics.org*](http://www.reproducible-bioinformatics.org/) project and provides single cell analysis functionalities within the reproducible rules described by Sandve et al. [[*PLoS Comp Biol. 2013*](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285)]. CASC is designed to provide a complete workflow (Figure \ref{fig:fig.1}) for cell-subpopulation discovery. 

```{r fig.1, fig.cap="CASC workflow", echo=FALSE, eval=TRUE, out.width="70%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/casc_workflow.jpeg')

```


The workflow allows the direct analysis of fastq files generated with [*10X Genomics platform*](https://www.10xgenomics.com/) or [*InDrop technology*](https://1cell-bio.com/) or a count matrix having as column cell identifier and as row names ENSEMBL gene annotation. In the following paragraphs we will describe the fuctionalities of CASC workflow.
\newline


## Minimal hardware requirements to run CASC
The RAM and cores requirements are dependent on the data set under analysis, e.g. 500-600 cells can be effectively analysed using the hardware described by Beccuti [[*Bioinformatics 2018*](https://academic.oup.com/bioinformatics/article/34/5/871/4562334)]: 32 Gb RAM and 2.6 GHz Core i7 6700HQ with 8 threads. The analysis time can be significantly improved increasing the number of cores using a multi-core achitecture system, cluster implementation of the workflow using [*swarm*](https://docs.docker.com/engine/swarm/) is under implementation. 

## Installation

The installation for the package is shown below.
\newline
```{r, echo=TRUE, eval=FALSE}
install.packages("devtools")
library(devtools)
install_github("kendomaniac/casc")

# downloading the required containers
library(casc)
downloadContainers()


```


## Counts generation

### inDrop seq

inDrop was originally pulished by Klein [[*Cell 2015*](https://www.ncbi.nlm.nih.gov/pubmed/26000487)]. Then, two year after that, the authors published the detailed protocol in [[*Zilionis et al. Nature Protocols 2017*](https://www.ncbi.nlm.nih.gov/pubmed/27929523)], which has different primer design comparing to the orginal paper (Figure \ref{fig:fig.2}). 

```{r fig.2, fig.cap="inDrop library structure", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/indrop_v2.jpeg')
```


The analysis shown below is based on the protocol in Zilionis [[*Nature Protocols 2017*](https://www.ncbi.nlm.nih.gov/pubmed/27929523)], which is the version 2 of the inDrop technology. According to the [*inDrop github page*](https://github.com/indrops/indrops), there is a version 3, but the oligos and library structures are exactly the same as version 2, except the sequencing mode changed.

In version 2, three different reads are generated: 

```{r fig.3, fig.cap="inDrop v2", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/indropv2.jpg')
```


In version 3, four different reads are generated:

```{r fig.4, fig.cap="inDrop v3", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/indropv3.jpg')
```



#### inDrop data analysis

- **inDropseq**:
    + Creating a reference genome for inDrop V2: **indropIndex**
    + From fastq to UMI counts using inDrop workflow: **indropCounts**


The function *indropIndex* is available to generate the index files required for reads mapping and annotation.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

library(casc)
#running indropCounts index build
indropIndex(group="docker", index.folder=getwd(),
 ensembl.urlgenome="ftp://ftp.ensembl.org/pub/release-87/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna.toplevel.fa.gz",
ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-87/gtf/mus_musculus/Mus_musculus.GRCm38.87.gtf.gz")

```

\fontsize{10}{10}\selectfont
The function *indropCounts* starts from inDrop V2 library fastqs and generates UMI counts.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

system("wget 130.192.119.59/public/testMm_S0_L001_R1_001.fastq.gz")
system("wget 130.192.119.59/public/testMm_S0_L001_R2_001.fastq.gz")
library(casc)
indropCounts(group="docker", scratch.folder="/data/scratch", fastq.folder=getwd(),
        index.folder="/data/genomes/indropMm10", sample.name="testMm", split.affixes="S0_L001",
        bowtie.index.prefix="genome", M=10, U=2, D=400, low.complexity.mask="False")

```
\fontsize{10}{10}\selectfont

### 10XGenomics

- **10XGenomics**:
    + Downloading a reference genome for 10XGenomics
    + Converting fastq in UMI counts matrix using cellranger: **cellrangerCount**


[Cellranger](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/algorithms/overview) is the 10xGenomics tool allowing the conversion of the fastq generated from 10XGenomics platform into a count matrix. 

Genome indexes downloadable from 10Xgenomics repository:
\newline
```{r, echo=TRUE, eval=FALSE}
setwd("/data/genomes/cellranger_hg38")
#getting the hg38 human genome cellranger index 
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-GRCh38-2.1.0.tar.gz")
setwd("/data/genomes/cellranger_hg19")
#getting the hg19 human genome cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-hg19-2.1.0.tar.gz")
setwd("/data/genomes/cellranger_mm10")
#getting the mm10 mouse genome cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-mm10-2.1.0.tar.gz")
setwd("/data/genomes/cellranger_hg19mm10")
#getting the human and mouse cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-hg19-and-mm10-2.1.0.tar.gz")
```

\fontsize{10}{10}\selectfont
The function *cellrangerCount* starts from 10Xgenomics library fastqs and generates UMI counts.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

home <- getwd()
library(casc)
downloadContainers()
setwd("/data/genomes/cellranger_hg19mm10")
#getting the human and mouse cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-hg19-and-mm10-2.1.0.tar.gz")
setwd(home)
# downloading 100 cells 1:1 Mixture of Fresh Frozen Human (HEK293T) and Mouse (NIH3T3) Cells
system("wget http://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_100/hgmm_100_fastqs.tar")
system("tar xvf hgmm_100_fastqs.tar")
# The cellranger analysis is run without the generation of the secondary analysis
cellrangerCount(group="docker",  transcriptome.folder="/data/genomes/cellranger_hg19mm10",  
                fastq.folder="/data/test_cell_ranger/fastqs",  expect.cells=100, 
                nosecondary=TRUE, scratch.folder="/data/scratch")
```
\fontsize{10}{10}\selectfont
 
The analysis done above took 56.4 mins on an [SeqBox](www.seqbox.com), equipped with an Intel i7-6770HQ (8 threads), 32 Gb RAM and 1Tb SSD.

The output of the above analysis are two cell counts matrices **results_cellranger.cvs** and **results_cellranger.txt** an a folder called **results_cellranger**, which contain the full cellranger output.

## Counts matrix editing

This paragraph describes a set of functions that can be used to remove low quality cells and non-informative genes.

- **Counts manipulation**:
    + Removing non informative genes: **filterZeros**
    + Checking the genes versus total number of UMI: **genesUmi**
    + Removing low quality cells: **lorenzFilter**
    + Data normalization: **scnorm**, minimal requirements 10K counts/cell, works best with whole transcripts sequencing
    + Data normalization: **umiNorm**, global normalization methods TMM and RLE are suitable for UMI data
    + ENSEMBL annotation and mitochodrial/ribosomal protein genes removal: **scannobyGtf**
    + Converting a count table in log10: **counts2log**
    + Removing cell cycle bias: **recatPrediction**/**ccremove**



### Removing non informative genes

The function **filterZeros** retains all genes that have cells without a user defined fraction of zeros (between 0 and 1, where 1 indicate only genes without 0s are retained, and 0 insted indicates that genes with at least a value different from zero are retained) and plots the frequency distribution of genes with counts in the cells. 

**IMPORTANT**: In case user would like to apply cell quality filter, e.g. *lorenzFilter*, it is covenient to remove only genes with 0 counts in all cells, i.e. threshold=0 (Figure \ref{fig:fig.5}).
\newline
```{r, echo=TRUE, eval=FALSE}

system("wget http://130.192.119.59/public/testSCumi_mm10.csv.zip")
unzip("testSCumi_mm10.csv.zip")
tmp <- read.table("testSCumi_mm10.csv", sep=",", header=T, row.names=1)
dim(tmp)
#27998   806
write.table(tmp, "testSCumi_mm10.txt", sep="\t", col.names=NA)
filterZeros(data.folder=getwd(),counts.matrix="testSCumi_mm10.txt", threshold=0)
#Out of 27998 genes 11255 are left after removing genes with no counts
#output is filtered_testSCumi_mm10.txt

```

```{r fig.5, fig.cap="Non zeros distribution in full table, orange, and filtered table, blue", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/filterZero.jpeg')
```

### Plotting genes numbers versus total UMIs in each cell

To estimate the overall amount of genes detectable in each cell, the function *genesUmi* produces a plot of the genes number with respect to total number of UMI for each cell. The number of UMIs required to indicate that a gene is detected in a cell are defined by user. We suggest to use at least 3 UMI as minimal threshold to consider a gene called present in a cell.

```{r, echo=TRUE, eval=FALSE}

library(casc)
genesUmi(data.folder=getwd(), counts.matrix="filtered_testSCumi_mm10.txt", umiXgene=3)

```

In figure \ref{fig:fig.6} it is shown the distribution of genes in cells for filtered_testSCumi_mm10.txt counts table. 

```{r fig.6, fig.cap="genesUmi output", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/genesUMI.jpg')
```

### Identifying and removing cell low-quality outliers

To identify outlier libraries, [*Diaz et al. 2016*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/) developed a strategy to estimate genes expressed at background levels in a given sample. Then samples whose background fraction is significantly larger than average is filtered out (Lorenz statistics). Specifically, samples that had a small q-value for Lorenz statistic had low complexity, as measured by Gini-Simpson index, and/or they had low coverage, as estimated by the Good-Turing statistic [*Diaz et al.2016*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/). Furthermore, Lorenz statistics correlates with live-dead staining, Pearson-correlation 0.7 [*Diaz et al.2016*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/). We have implemented the Lorenz statistics in CASC **lorenzFilter** function.
\newline
```{r, echo=TRUE,eval=FALSE}

#IMPORTANT: full path to the file MUST be cell count file included!
library(casc)
# the p_value indicate the probability that a low quality cell is retained in the dataset filtered on the basis of Lorenz Statistics.
lorenzFilter(group="docker",scratch.folder="/data/scratch/", 
               file=paste(getwd(),"filtered_testSCumi_mm10.txt", sep="/"),
               p_value=0.05, separator='\t')

tmp0 <- read.table("filtered_testSCumi_mm10.txt", sep="\t", header=T, row.names=1)
#806 cells

tmp <- read.table("lorenz_filtered_testSCumi_mm10.txt", sep="\t", header=T, row.names=1)
#785 cells

```

In the example above 21 cells were removed because of their low quality (Figure \ref{fig:fig.7}). 

```{r fig.7, fig.cap="Effect of Lorenz filtering, cells shown in blue have been discarded because of their low quality.", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/lorenz_filter.jpg')
```

### Annotation and mitocondrial/ribosomal protein genes removal

The function *scannoByGtf* allows the annotation of single-cell matrix, if ENSEMBL gene ids are provided. The function requires the ENSEMBL GTF of the organism under analysis and allows the selection of specific annotation biotypes, e.g. protein_coding.
\newline
```{r, echo=TRUE, eval=FALSE}

#running annotation and removal of mit and ribo proteins genes
system("wget ftp://ftp.ensembl.org/pub/release-92/gtf/mus_musculus/Mus_musculus.GRCm38.92.gtf.gz")
system("gunzip Mus_musculus.GRCm38.92.gtf.gz")
scannobyGtf(group="docker", file=paste(getwd(),"lorenz_filtered_testSCumi_mm10.txt",sep="/"),
                    gtf.name="Mus_musculus.GRCm38.92.gtf", biotype="protein_coding", 
                    mt=TRUE, ribo.proteins=TRUE,umiXgene=3)

```


Ribosomal RNA and ribosomal proteins represent a significant part of the cell cargo. Large cells and actively proliferating cells will have respectively more ribosomes and more active ribosome synthesis. Thus, ribosomal proteins expression might represent a major confunding factor in cluster formation between active and dormient cells. Furthermore, the main function of mitochondria is to produce energy through aerobic respiration. The number of mitochondria a cell possesses depends on its metabolic demands. This might also affect clustering favoring the separation between active and dormient cells with respect to functional differences between subpopulations.
*scannobyGtf* allows also the removal of mitocondrial and ribosomal protein genes.
\newline
```{r, echo=TRUE, eval=FALSE}

library(casc)
scannobyGtf(group="docker", file=paste(getwd(),"lorenz_filtered_testSCumi_mm10.txt",sep="/"),
                    gtf.name="Mus_musculus.GRCm38.92.gtf", biotype="protein_coding", 
                    mt=FALSE, ribo.proteins=FALSE,umiXgene=3)

```

In figure \ref{fig:fig.8} is shown the effect of the removal of both mitocondrial and ribosomal protein genes. It is notable that, in this specific experiment, in cells with less than 1000 UMI nearly all detected genes were only mitocondrial and ribosomal protein genes. This filter is suitable to identify cells which do not contain any informative gene other the mitocondrial and ribosomal proteins. However, in case the difference between resting and actively proliferating cells are an important element of cell sub-population discovery this filter should not be applied.

```{r fig.8, fig.cap="Removing mithocondrial and ribosomal proteins genes, in blue is shown the dataset after removal of mitocondrial and ribosomal protein genes.", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/noMT-rib.jpg')
```


### Top expressed genes

For clustering purposes user might decide to use the top expressed genes. The function *topX* select the X top expressed genes given a user defined threshold. The function also produces a pdf file gene_expression_distribution.pdf showing the changes in the UMIs/gene expression distribution upon *topX* filtering.

```{r, echo=TRUE, eval=FALSE}
 
library(casc)
genesUmi(data.folder=getwd(), counts.matrix="lorenz_filtered_testSCumi_mm10.txt", umiXgene=3)
topx(data.folder=getwd(),file.name="lorenz_filtered_testSCumi_mm10.txt",threshold=10000, logged=FALSE)
genesUmi(data.folder=getwd(), counts.matrix="lorenz_filtered_testSCumi_mm10_10000.txt", umiXgene=3)

```


### Data normalization

[*The best way to normalize single-cell RNA-seq data has not yet been resolved*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5549838/), expecially in the case of UMI data. We inserted in our workflow two possible options:

- [SCnorm](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473255/), which works best with whole transcript data.

- [scone](https://www.biorxiv.org/content/early/2017/12/16/235382), which provides different global scaling methods that can be applyed to UMI single-cell data.

#### SCnorm

[*SCnorm*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473255/) performs a quantile-regression based approach for robust normalization of single-cell RNA-seq data.  SCnorm groups genes based on their count-depth relationship then applies a quantile regression to each group in order to estimate scaling factors which will remove the effect of sequencing depth from the counts.

IMPORTANT: SCnorm is not intended for datasets with more than ~80% zero counts, because of lack of algoritm convergency in these situations. 

##### Check counts-depth relationship

Before normalizing using **scnorm**, it is advised to check the data count-depth relationship.
If all genes have a similar relationship then a global normalization strategy such as median-by-
ratio in the DESeq package or TMM in edgeR will also be adequate. However, when the count-depth relationship varies among genes using global scaling strategies leads to poor normalization. In these cases the normalization provided by SCnorm is recommended.

**checkCountDepth** provides a wrapper, in CASC, for the checkCountDepth of the [*SCnorm package*](https://github.com/rhondabacher/SCnorm), which estimates the count-depth relationship for all genes.
\newline
```{r, echo=TRUE, eval=FALSE}

#this specific example is an UMI counts table made of 12 cells having at least 10K UMIs/cell.
system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
conditions=rep(1,12)
checkCountDepth(group="docker", file=paste(getwd(), "example_UMI.txt", sep="/"),
     conditions=conditions, FilterCellProportion=0.1, FilterExpression=0,
     ditherCounts=TRUE, outputName="example_UMI", nCores=8)

```

The output is a PDF (Figure \ref{fig:fig.9}), providing a view of the counts distribution of the data, and a file selected.genes.txt, which contains the genes selected to run the analysis.

```{r fig.9, fig.cap="checkCountDepth output plot", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/checkCountDepth0.jpg')
```


#### scnorm

the **scnorm** function execute SCnorm from [*SCnorm package*](https://github.com/rhondabacher/SCnorm), which normalizes  across  cells  to  remove  the effect  of  sequencing  depth  on  the  counts  and  return  the  normalized expression count.
\newline
```{r, echo=TRUE, eval=FALSE}

system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
#this specific example is an UMI counts table made of 12 cells having at least 10K UMIs/cell.
conditions=rep(1,12)
scnorm(group="docker", file=paste(getwd(), "example_UMI.txt", sep="/"),
     conditions=conditions,outputName="example_UMI", nCores=8, filtercellNum=10,
     ditherCount=TRUE, PropToUse=0.1, PrintProgressPlots=TRUE, FilterExpression=1)

```

The output files are a tab delimited file containing the normalized data, with the prefix **normalized_**, and **discarded_genes.txt**, which contains the discarded genes.

```{r fig.10, fig.cap="Effect of the SCnorm on the dataset in Figure 9", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/scnorm.jpeg')
```

#### scone

scone package embeds:

- Centered log-ratio (**CLR**) normalization 

- Relative log-expression (**RLE**; DESeq) scaling normalization

    + the scaling factors are calculated for each lane as median of the ratio, for each gene, of its read count of its geometric mean across all lanes. 

- Full-quantile normalization

    + quantile normalization is a technique for making two or more distributions identical in statistical properties. To quantile normalize two or more samples to each other, sort the samples, then set to the average (usually, arithmetic mean) of the samples. So the highest value in all cases becomes the mean of the highest values, the second highest value becomes the mean of the second highest values, and so on.

- Simple deconvolution normalization 

- Sum scaling normalization

    + Gene counts are divided by the total number of mapped reads (or library size) associated with their lane and multiplied by the mean total count across all the samples of the dataset.

- Weighted trimmed mean of M-values (**TMM**, edgeR) scaling normalization

    + to compute the TMM factor, one lane is considered a reference sample and the others test samples, with TMM being the weighted mean of log ratios between test and reference, after excluding the most expressed genes and the genes with the largest log ratios. 

- Upper-quartile (**UQ**) scaling normalization

    + the total counts are replaced by the upper quartile of counts different from 0 in the computation of the normalization factors.


```{r, echo=TRUE, eval=FALSE}

#Weighted trimmed mean of M-values (TMM) scaling normalization
system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
umiNorm(group="docker", file=paste(getwd(), "example_UMI.txt", sep="/"),
       outputName="example_UMI", normMethod="TMM_FN")

```

**IMPORTANT**: Only log10 conversion is required for the counts table when [*SIMLR*](https://www.ncbi.nlm.nih.gov/pubmed/28263960) clustering is performed.

### Converting a count table in log10

The function **counts2log** can convert a count table in a log10 values saved in a comma separated or tab delimited file.

```{r, echo=TRUE, eval=FALSE}

counts2log(file=paste(getwd(), "example_UMI.txt", sep="/"), log.base=10)

```

### Removing cell cycle bias

Single-cell RNA-Sequencing measurement of expression often suffers from large systematic bias. A major source of this bias is the cell cycle, which introduces large within-cell-type heterogeneity that can obscure the differences in expression between cell types. [*Barron and Li*](https://www.nature.com/articles/srep33892) developed in 2016 a R package called [*ccRemover*](https://cran.r-project.org/web/packages/ccRemover/index.html) which removes cell cycle effects and preserves other biological signals of interest (Figure \ref{fig:fig.11}).

```{r fig.11, fig.cap="Removal of cell cycle bias as described in Barron and Li. (Sci. Rep. 2016). A) PCA analysis of Buettner et al. (Nat.Biotechnol. 2015) raw dataset, B) PCA analysis of ccRemover cell-cycle normalized dataset. Figure edited from supplementary data in Barron and Li (Sci. Rep. 2016).", echo=FALSE, eval=TRUE, out.width="50%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/barron2016.jpeg')
```

However, the critical point is if it is really needed the removal of cell cycle effect. [*reCAT*](https://www.nature.com/articles/s41467-017-00039-z) is a modelling framework for unsynchronized single-cell transcriptome data that can reconstruct cell cycle time-series.  Thus, we use reCAT cell cycle prediction step to check if we can detect a clear cell cycle effect in a dataset (Figure \ref{fig:fig.12}). In such case, we use ccRemover to eliminate such bias.

```{r fig.12, fig.cap="reCAT prediction of cell cycle in Buettner et al. (Nat.Biotechnol. 2015) dataset. Figure extracted from reCAT github", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/ola_2i_bayes.png')
```

- **Removing cell cycle bias**:
    + Reconstructing cell cycle time-series: **recatPrediction**
    + Removing cell cycle effect: **ccRemover**

**reCAT** prediction step is implemented in CASC in the function **recatPrediction**, which requires a data set annotated using scannobyGtf.

**ccRemover** is implemented in CASC in the function **ccRemove**, which also requires a data set annotated using scannobyGtf. **IMPORTANT**: The output of ccRemover does not require log transformation to be used in clustering analysis.

As example of this approach we used the dataset published by [*Buettner et al Nat.Biotechnol. 2015*](https://www.ncbi.nlm.nih.gov/pubmed/25599176), which contains naive-T-cells and T-helper2-cells mixed togheter and sorted on the basis of the cell cycle state.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}
#preparing the data for the analysis
 system("wget http://130.192.119.59/public/buettner_G1G2MS_counts.txt.zip")
 unzip("buettner_G1G2MS_counts.txt.zip")

#annotatiing the data set to obtain the gene names in the format ensemblID:symbol 
scannobyGtf(group="docker", file=paste(getwd(),"buettner_G1G2MS_counts.txt",sep="/"),
                    gtf.name="Mus_musculus.GRCm38.92.gtf", biotype="protein_coding", 
                    mt=TRUE, ribo.proteins=TRUE,umiXgene=3)

#selecting the top 10000 most expressed genes
topx(data.folder=getwd(),file.name="annotated_buettner_G1G2MS_counts.txt",threshold=10000, logged=FALSE)

#running cell cycle prediction
recatPrediction(group="docker",scratch.folder="/data/scratch",file=paste(getwd(), "annotated_buettner_G1G2MS_counts_10000.txt", sep="/"), 
                separator="\t", geneNameControl=1, window=10, seed=111)

#removing cell cycle effect
ccRemove(group="docker" , scratch.folder="/data/scratch",
        file=paste(getwd(),"annotated_buettner_G1G2MS_counts_10000.txt", sep="/"), separator="\t",
        seed=111, cutoff=3, species="mouse", rawCount=1)

```

\fontsize{10}{10}\selectfont
The analysis above took respectively XXX mins for recatPrediction and 28 mins for ccRemove on a [SeqBox](www.seqbox.com), equipped with an Intel i7-6770HQ (8 threads), 32 Gb RAM and 1Tb SSD. 

ccRemover analysis produces a data normalized matrix, ready for clustering. The matrix can be identify by the prefix **LS_cc_**.

