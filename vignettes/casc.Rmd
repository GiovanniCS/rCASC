---
title: "Single Cell workflow"
author: "Luca Alessadri, Francesca Cordero, Marco Beccuti and Raffaele A Calogero"
output: 
  rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Single cell sequencing is a  recent technique, very powerful but not mature yet. Single cell sequencing data analysis is therefore a very dinamic field. The present workflow will undergo modifications on the basis of the availability of new tools and sequencing techniques.

The worflow is divided in two bocks: the first one designed to generate counts

![Counts generation](../inst/img/workflow0.jpeg)

and the second made to analyze counts for the identification of cell sub-population clusters. The dashed elements are those parts of the workflow not finished, yet.

![Counts analysis](../inst/img/workflow1.jpeg)

## Counts generation

- **inDropseq**:
    + Creating a reference genome for inDrop V2:
    + From fastq to UMI counts using inDrop workflow: **indropCounts**

## inDrop seq

The function indropCounts start for inDrop V2 library and convert fastq to UMI counts.

```{r, echo=TRUE, eval=FALSE}

indropCounts(group="docker", scratch.folder="/data/scratch", fastq.folder=getwd(),
        index.folder="/data/genomes/mm10indrop", sample.name="C2", split.affixes="S2_L001",
        bowtie.index.prefix="Mus_musculus.GRCm38.85.index", M=10, U=2, D=400, low.complexity.mask="False")

```



## Counts analysis

- **Counts manipulation**:
    + Removing non informative genes: **filterZeros**
    + Data normalization: **scnorm**
    + Imputing dropouts: **cascImpute**
    + Converting a count table in log10: **counts2log**
- **Cell filtering**:
    + Removing low quality cells: **lorenzFilter**



## Counts manipulation

### Removing non informative genes

The function **filterZeros** retains all genes that have cells without counts, given a theshold fraction (between 0 and 1, where 1 indicate only gens without 0s are retained) and plot the frequency distribution of genes with counts in the cells. If threshold is set to 0 only genes that do not have any expression in any of the cells are removed.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
filterZeros(data.folder=getwd(),counts.matrix="singlecells_counts.txt", threshold=0)

```


### Data normalization

SCnorm (as detailed in Bacher et al.) performs a quantile-regression based approach for robust normalization of single-cell RNA-seq data.  SCnorm groups genes based on their count-depth relationship then applies a quantile regression to each group in order to estimate scaling factors which will remove the effect of sequencing depth from the counts.

IMPORTANT: SCnorm is not intended for datasets with more than ~80% zero counts, often K will not converge in these situations. In our test ditherCounts = TRUE parameter frequently generate an error. If 1000 of more cells are 

#### Check counts-depth relationship

Before normalizing using **scnorm**, it is advised to check the data count-depth relationship. **checkCountDepth** provides a wrapper, in CASC, for the checkCountDepth of the [**SCnorm package**](https://github.com/rhondabacher/SCnorm), which estimates the count-depth relationship for all genes.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
conditions=rep(1,288)
checkCountDepth(group="docker", data.folder=getwd(), counts.matrix="singlecells_counts.txt", conditions=conditions, outputName="singlecells_counts", nCores=8)

```

The output is a PDF that provides a view of the counts distribution of the data.



#### scnorm

the **scnorm** function execute SCnorm of the [**SCnorm package**](https://github.com/rhondabacher/SCnorm), which normalizes  across  cells  to  remove  the effect  of  sequencing  depth  on  the  counts  and  return  the  normalized expression count.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
conditions=rep(1,288)
scnorm(group="docker", data.folder=getwd(),counts.matrix="singlecells_counts.txt", conditions=conditions,outputName="singlecells_counts", nCores=8, filtercellNum=10, PropToUse=0.1)

```

The output is a PDF that provides a view of effects of normalization, and Rda file containing the full output of **SCnorm** and a tab delimited file containing the normalized data.

Setting PropToUse to 0.1 was particularly useful with large UMI based datasets. Proportion of genes closest to the slope mode used for the group fitting. This number affects a lot speed.

**IMPORTANT NOTE:** for large number of cells, e.g. 1000 or more, setting filtercellNum to low numbers, e.g. 10, makes the scnorm running to an indefinite time. We suggest to make various tests to see which is a suitable number of non-zero genes passed via filtercellNum parameter.


### Imputing dropouts

the **cascImpute** function execute scImpute of the [**scImpute package**](https://github.com/Vivianstats/scImpute), which impute the dropout values in scRNA-seq data.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
cascImpute(group="docker", data.folder=getwd(), counts.matrix="singlecells_counts.txt", drop.thre=0.5, cores=8)

#Modifying drop.thre value A quick version of the imputing can be used to refine drop.thre values indicating refining=TRUE. It has to be done in the same folder where the frst run was done.
cascImpute(group="docker", data.folder=getwd(), counts.matrix="singlecells_counts.txt", drop.thre=0.3, cores=8, refining=TRUE)
```

The output is a matrix file containing the imputed data. 



### Converting a count table in log10

The function **counts2log** can convert a count table in a log10 values saved in a comma separated file which is the input of CASC.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
counts2log(counts.matrix="singlecells_counts.txt", data.folder=getwd(), 
           log.base=10, type="txt")
```



## Cell filtering

### Identifying outlier libraries

To identify outlier libraries, [Diaz et al.2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/) developed a strategy to estimate genes expressed at background levels in a given sample. Then samples whose background fraction is significantly larger than average is filtered out (Lorenz statistics). Furthermore, this statistics correlates with live-dead staining, Pearson-correlation 0.7 [Diaz et al.2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/).  

```{r, echo=TRUE,eval=FALSE}

lorenzFilter(group="docker",scratch.folder="path/of/scratch/folder",
           data.folder="path/of/data/folder",matrixName="matrixName",
           p_value=0.05,format="txt",separator='\t')

```



#### Defining the optimal number of clusters

An important step in the single-cell transcriptome analysis is to group cells that belong to the same type based on gene expression patterns [Usoskin et al, Pollen et al, Kolodziejczyk et al].
This can be done using supervised and unsupervised clustering. A lot of tools are actually available for single-cell transcriptome clustering [ref]. At the present time we have implemented tSne and SIMLR.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/log10_singlecells_counts.csv.gz")
system("gzip -d log10_singlecells_counts.csv.gz")

cascKoptimization(group="docker", scratch.folder="/Users/raffaelecalogero/Desktop/scratch", data.folder=getwd(),
counts.matrix="log10_singlecells_counts.csv", permutations=20, blocks.permutations=2, core=0, bootstrap.fraction=10, k.min=2, k.max=4, totIdentity=80, clusterIdentity=80)

```

The function **cascKoptimization** run SIMLR [Wang et al] using a range of clusters and produces as output two violin plots:

- silhouette.pdf: Silhouette refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object lies within its cluster. Here instead of using the average silhouette we represent the silhouette values distribution using a violin plot. Thus, silhouette distributions being skewed to the positive values and with short negative tail is representative of a consistent cluster. In the example below, fig. A, it seems that 4 clusters are the most consistent by silhouette analysis.


- cell.stability.pdf: Cell stability plot represent the distribution of the fraction of times, given a N number of permutations, that the cell are stabily localized in a cluster. The example below, fig. B, 3 clusters are characterized by an higher cell stability with respect to 4 clusters. 

Taking in account the two plots and the clusters structure observed for 3 and 4 clusters, fig C and D, it is clear that 4 clusters provide a better separation between cells but keeping very high the cell permanence in a cluster.



The function **cascOutputReformat** use SilhouetteParameters.csv (the file containing the cell silhouette scores), mainVector.csv (the file that associates each cell to a specific SIMLR cluster), scoreVector.csv (the file associating each cell to a specific cell stability score), dataPlot.csv (containing SIMLR component 1 and 2 cohordinates) to generate a summary file called **summary_table.csv**.

```{r, echo=TRUE, eval=FALSE}
 #downloading fastq files
system("wget http://130.192.119.59/public/example.zip")
unzip("example.zip")
setwd("./example")
cascOutputReformat(data.folder=getwd())
```











